<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>publications &amp; articles | Jaspreet  Ranjit</title>
    <meta name="author" content="Jaspreet  Ranjit">
    <meta name="description" content="Jaspreet Ranjit's Homepage
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04">
    <!-- <link rel="stylesheet" href="/assets/css/mdb.min.css?62a43d1430ddb46fc4886f9d0e3b49b8"> -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%98%80%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e">
    <link rel="canonical" href="https://jr4fs.github.io/publications/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark">
    <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script>
    <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Jaspreet </span>Ranjit</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/research/">research</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">publications &amp; articles<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/internships/">internships</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/service/">service &amp; projects</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
<div class="post">

  <header class="post-header">
    <h1 class="post-title">publications &amp; articles</h1>
    <p class="post-description"></p>
  </header>

  <article>
    <!-- _pages/publications.md -->
<div class="publications">

<h2 class="bibliography">2025</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
<div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/nvdrs-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/nvdrs-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/nvdrs-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/nvdrs.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="nvdrs.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>
<!-- Entry bib key -->
        <div id="ranjit2025interventions" class="col-sm-8">
        <!-- Title -->
        <div class="title">Uncovering Intervention Opportunities for Suicide Prevention with Language Model Assistants</div>
        <!-- Author -->
        <div class="author">
        

        <em>Jaspreet Ranjit</em>, Hyundong J. Cho, Claire J. Smerdon, and
          <span class="more-authors" title="click to view 5 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '5 more authors' ? 'Yoonsoo Nam, Myles Phung, Jonathan May, John R. Blosnich, Swabha Swayamdipta' : '5 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">5 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In EAAMO Poster Presentation</em>, 2025
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            
            <a class="award btn btn-sm z-depth-1 rounded" role="button">Runner up for best doctoral oral presentation @ ShowCAIS’25</a>
          
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://github.com/dill-lab/interventions_lm_assistants" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          
          
          
          
          <!-- Hidden Award block -->
          <div class="award hidden d-print-inline">
            <p></p>
<p>Runner up for best doctoral oral presentatino at ShowCAIS 2025</p>

          </div>
        
        
          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The National Violent Death Reporting System (NVDRS) documents in-
formation about suicides in the United States, including free text narra-
tives (e.g., circumstances surrounding a suicide). In a demanding public
health data pipeline, annotators manually extract structured information
from death investigation records following extensive guidelines developed
painstakingly by experts. In this work, we facilitate data-driven insights
from the NVDRS data to support the development of novel suicide inter-
ventions by investigating the value of language models (LMs) as efficient
assistants to these (a) data annotators and (b) experts. We find that LM
predictions match existing data annotations about 85% of the time across
50 NVDRS variables. In the cases where the LM disagrees with existing an-
notations, expert review reveals that LM assistants can surface annotation
discrepancies 38% of the time. Finally, we introduce a human-in-the-loop
algorithm to assist experts in efficiently building and refining guidelines for
annotating new variables by allowing them to focus only on providing feed-
back for incorrect LM predictions. We apply our algorithm to a real-world
case study for a new variable that characterizes victim interactions with
lawyers and demonstrate that it achieves comparable annotation quality
with a laborious manual approach. Our findings provide evidence that LMs
can serve as effective assistants to public health researchers who handle
sensitive data in high-stakes scenarios.</p>
          </div>
        </div>
      </div>
</li></ol>
<h2 class="bibliography">2024</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
<div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/oath-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/oath-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/oath-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/oath.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="oath.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>
<!-- Entry bib key -->
        <div id="ranjit2024oath" class="col-sm-8">
        <!-- Title -->
        <div class="title">OATH-Frames: Characterizing Online Attitudes Towards Homelessness via LLM Assistants</div>
        <!-- Author -->
        <div class="author">
        

        <em>Jaspreet Ranjit</em>, Brihi Joshi, Rebecca Dorn, and
          <span class="more-authors" title="click to view 6 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '6 more authors' ? 'Laura Petry, Olga Koumoundouros, Jayne Bottarini, Peichen Liu, Eric Rice, Swabha Swayamdipta' : '6 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">6 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of EMNLP</em>, 2024
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            
            <a class="award btn btn-sm z-depth-1 rounded" role="button">Outstanding Paper Award @ EMNLP 2024; Best Poster @ ShowCAIS’24</a>
          
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://dill-lab.github.io/oath-frames/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Blog</a>
            <a href="https://github.com/dill-lab/oath-frames" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>
          
          
          
          
          
          <!-- Hidden Award block -->
          <div class="award hidden d-print-inline">
            <p></p>
<p>Outstanding Paper Award @ EMNLP 2024; Jaspreet received a <a href="https://sites.google.com/usc.edu/showcais-2024/awards?authuser=0" rel="external nofollow noopener" target="_blank">best poster award</a> at USC CAIS’s annual symposium, <a href="https://sites.google.com/usc.edu/showcais-2024/" rel="external nofollow noopener" target="_blank">ShowCAIS</a> in Spring 2024.</p>

          </div>
        
        
          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Homelessness in the U.S. is widespread; individual beliefs and attitudes towards homelessness—often expressed on social media are complex and nuanced (e.g. critical as well as sympathetic). Such attitudes can be challenging to summarize at scale, obfuscating the broader public opinion which advocacy organizations use to guide public policy and reform efforts. Our work proposes an approach to enable a large-scale study on homelessness via two major contributions. First, with the help of domain experts in social work and their trainees, we characterize Online Attitudes towards Homelessness in nine hierarchical frames (OATH-Frames) on a collection of 4K social media posts. Further, in an effort to ease the annotation of these frames, we employ GPT-4 as an LLM assistant to the experts; GPT-4 + Expert annotation presents an attractive trade off owing to a 6.5× speedup in annotation time despite only incurring a 2 point F1 difference in annotation performance. Our effort results in a collection of 8K social media posts labeled by domain and trained experts (with and without GPT-4 assistance). Second, using predicted OATH-Frames on a Flan-T5-Large model trained on our data, we perform a large-scale analysis on 2.4M posts on homelessness. We find that posts that contain mentions of west coast states express more harmful generalizations of people experiencing homelessness (PEH) compared to posts about east coast states. We also find marked differences in attitudes across vulnerable populations as they are compared to PEH as being either more or less deserving of aid.</p>
          </div>
        </div>
      </div>
</li></ol>
<h2 class="bibliography">2023</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
<div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/variation_gender_biases-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/variation_gender_biases-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/variation_gender_biases-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/variation_gender_biases.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="variation_gender_biases.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>
<!-- Entry bib key -->
        <div id="ranjit2023variation" class="col-sm-8">
        <!-- Title -->
        <div class="title">Variation of Gender Biases in Visual Recognition Models Before and After Finetuning</div>
        <!-- Author -->
        <div class="author">
        

        <em>Jaspreet Ranjit</em>, Tianlu Wang, Baishakhi Ray, and
          <span class="more-authors" title="click to view 1 more author" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '1 more author' ? 'Vicente Ordonez' : '1 more author';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">1 more author</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Workshop on Algorithmic Fairness through the Lens of Time at NeuRIPS</em>, 2023
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://arxiv.org/abs/2303.07615" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
          </div>
          
          
          
          
          
        
          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We introduce a framework to measure how biases change before and after fine-tuning a large scale visual recognition model for a downstream task. Deep learning models trained on increasing amounts of data are known to encode societal biases. Many computer vision systems today rely on models typically pretrained on large scale datasets. While bias mitigation techniques have been developed for tuning models for downstream tasks, it is currently unclear what are the effects of biases already encoded in a pretrained model. Our framework incorporates sets of canonical images representing individual and pairs of concepts to highlight changes in biases for an array of off-the-shelf pretrained models across model sizes, dataset sizes, and training objectives. Through our analyses, we find that (1) supervised models trained on datasets such as ImageNet-21k are more likely to retain their pretraining biases regardless of the target dataset compared to self-supervised models. We also find that (2) models finetuned on larger scale datasets are more likely to introduce new biased associations. Our results also suggest that (3) biases can transfer to finetuned models and the finetuning objective and dataset can impact the extent of transferred biases.</p>
          </div>
        </div>
      </div>
</li></ol>
<h2 class="bibliography">2021</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
<div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/sce2vec-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/sce2vec-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/sce2vec-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/sce2vec.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="sce2vec.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>
<!-- Entry bib key -->
        <div id="sce2vec" class="col-sm-8">
        <!-- Title -->
        <div class="title">Scenario2Vector: Scenario Description Language Based Embeddings for Traffic Situations</div>
        <!-- Author -->
        <div class="author">
        

        Aron Harder, <em>Jaspreet Ranjit</em>, and Madhur Behl</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In Proceedings of the ACM/IEEE 12th International Conference on Cyber-Physical Systems</em>, 2021
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="https://doi.org/10.1145/3450267.3450544" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
          </div>
          
          
          
          
          
        
          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>A popular metric for measuring progress in autonomous driving has been the "miles per intervention". This is nowhere near a sufficient metric and it does not allow for a fair comparison between the capabilities of two autonomous vehicles (AVs). In this paper we propose Scenario2Vector - a Scenario Description Language (SDL) based embedding for traffic situations that allows us to automatically search for similar traffic situations from large AV data-sets. Our SDL embedding distills a traffic situation experienced by an AV into its canonical components - actors, actions, and the traffic scene. We can then use this embedding to evaluate similarity of different traffic situations in vector space. We have also created a first of its kind, Traffic Scenario Similarity (TSS) dataset which contains human ranking annotations for the similarity between traffic scenarios. Using the TSS data, we compare our SDL embedding -with textual caption based search methods such as Sentence2Vector. We find that Scenario2Vector outperforms Sentence2Vector by 13% ; and is a promising step towards enabling fair comparisons among AVs by inspecting how they perform in similar traffic situations. We hope that Scenario2Vector can have a similar impact to the AV community that Word2Vec/Sent2Vec have had in Natural Language Processing datasets.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
<div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/vimeo-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/vimeo-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/vimeo-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/vimeo.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="vimeo.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>
<!-- Entry bib key -->
        <div id="ranjitvimeo" class="col-sm-8">
        <!-- Title -->
        <div class="title">Uncovering bias in search and recommendations</div>
        <!-- Author -->
        <div class="author">
        

        <em>Jaspreet Ranjit</em>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Vimeo Engineering Blog on Medium</em>, 2021
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            
            <a href="https://medium.com/vimeo-engineering-blog/uncovering-bias-in-search-and-recommendations-751b01d1c874" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
          </div>
          
          
          
          
          
        
          
        </div>
      </div>
</li>
</ol>
<h2 class="bibliography">2019</h2>
<ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
<div class="col-sm-2 preview">
<figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/expedition-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/expedition-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/expedition-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/publication_preview/expedition.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="expedition.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">
  </picture>

</figure>
</div>
<!-- Entry bib key -->
        <div id="ranjitexpedition" class="col-sm-8">
        <!-- Title -->
        <div class="title">Anchorless object detection for 3D point cloud object detection</div>
        <!-- Author -->
        <div class="author">
        

        <em>Jaspreet Ranjit</em>, and Andrew Draganov</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Expedition Technology Blog</em>, 2019
        </div>
        <div class="periodical">
          
        </div>

          <!-- Links/Buttons -->
          <div class="links">
            
            <a href="https://www.exptechinc.com/my-summer-at-expedition-technology-as-a-machine-learning-intern/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a>
          </div>
          
          
          
          
          
        
          
        </div>
      </div>
</li></ol>

</div>

  </article>
</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Jaspreet  Ranjit. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="/assets/js/bootstrap.bundle.min.js"></script>
  <!-- <script src="/assets/js/mdb.min.js"></script> -->
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script>
  <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script>
  <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

    
  </body>
</html>
